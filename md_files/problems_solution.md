## –ü–µ—Ä–µ—Å–º–æ—Ç—Ä–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ (–¥–ª—è 1700 –ø—Ä–∏–º–µ—Ä–æ–≤)

### ‚úÖ **–ß—Ç–æ —Ç–µ–ø–µ—Ä—å –ù–ï —è–≤–ª—è–µ—Ç—Å—è –ø—Ä–æ–±–ª–µ–º–æ–π:**

1. **–†–∞–∑–º–µ—Ä –¥–∞—Ç–∞—Å–µ—Ç–∞** ‚Äî 1700 –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω–æ–≥–æ —Å—Ç–∏–ª—è.[^2][^3][^1]
2. **Overfitting —Ä–∏—Å–∫** ‚Äî —Å–Ω–∏–∂–µ–Ω (—Ö–æ—Ç—è –≤—Å—ë –µ—â—ë –Ω—É–∂–Ω–æ —Å–ª–µ–¥–∏—Ç—å –∑–∞ eval_loss).[^4][^1]

### üî¥ **–û—Å–Ω–æ–≤–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã (–∞–∫—Ç—É–∞–ª—å–Ω—ã–µ –¥–ª—è 1700 –ø—Ä–∏–º–µ—Ä–æ–≤):**

#### **1. –ö–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö –∏–∑ Telegram (–∫—Ä–∏—Ç–∏—á–Ω–æ!)**

–≠–∫—Å–ø–æ—Ä—Ç —á–∞—Ç–æ–≤ –∏–∑ Telegram —á–∞—Å—Ç–æ —Å–æ–¥–µ—Ä–∂–∏—Ç:

- **–ö–æ—Ä–æ—Ç–∫–∏–µ —Ä–µ–ø–ª–∏–∫–∏** ("–æ–∫", "—Å–ø—Å", "üëç") ‚Äî –Ω–µ –Ω–µ—Å—É—Ç —Å–º—ã—Å–ª–∞ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è.[^5][^6]
- **–û–±—Ä—ã–≤–∫–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞** ‚Äî –º–æ–¥–µ–ª—å –≤–∏–¥–∏—Ç –æ—Ç–≤–µ—Ç –±–µ–∑ –≤–æ–ø—Ä–æ—Å–∞ –∏–ª–∏ –Ω–∞–æ–±–æ—Ä–æ—Ç.[^6][^5]
- **–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π –º—É—Å–æ—Ä** ‚Äî timestamp, system messages, forwards.[^5][^6]
- **–ù–µ—Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–∞—Ä—ã** ‚Äî –º–Ω–æ–≥–æ –∫–æ—Ä–æ—Ç–∫–∏—Ö –æ—Ç–≤–µ—Ç–æ–≤, –º–∞–ª–æ —Ä–∞–∑–≤—ë—Ä–Ω—É—Ç—ã—Ö.[^7][^5]

**–ß—Ç–æ –¥–µ–ª–∞—Ç—å:**

```python
# –î–æ–±–∞–≤—å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é –≤ dataset_pipeline.py:
def is_valid_pair(prompt, completion):
    # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞
    if len(prompt.split()) < 3 or len(completion.split()) < 5:
        return False
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –º—É—Å–æ—Ä
    trash_patterns = ['ok', '–æ–∫', '—Å–ø–∞—Å–∏–±–æ', 'üëç', '—Ö–æ—Ä–æ—à–æ', '+']
    if completion.lower().strip() in trash_patterns:
        return False
    return True
```


***

#### **2. –ö–∞—Å—Ç–æ–º–Ω—ã–π instruction format vs native chat template**

–¢–≤–æ–π –∫–æ–¥ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç:

```python
### Instruction:
{prompt}
### Response:
{completion}
```

**–ü—Ä–æ–±–ª–µ–º–∞ –¥–ª—è Qwen2.5:**

- Qwen2.5-7B-Instruct –æ–±—É—á–∞–ª–∞—Å—å –Ω–∞ **ChatML format**:[^8][^9][^10]

```
<|im_start|>system
{system_prompt}<|im_end|>
<|im_start|>user
{user_message}<|im_end|>
<|im_start|>assistant
{assistant_response}<|im_end|>
```

- –ö–æ–≥–¥–∞ —Ç—ã –∏—Å–ø–æ–ª—å–∑—É–µ—à—å —Å–≤–æ–π —Ñ–æ—Ä–º–∞—Ç (\#\#\# Instruction / \#\#\# Response), –º–æ–¥–µ–ª—å **—Ç–µ—Ä—è–µ—Ç alignment** —Å –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–π.[^9][^10][^8]
- –≠—Ç–æ –æ–±—ä—è—Å–Ω—è–µ—Ç, –ø–æ—á–µ–º—É –º–æ–¥–µ–ª—å "–≥–æ–≤–æ—Ä–∏—Ç –æ –¥—Ä—É–≥–æ–º" ‚Äî –æ–Ω–∞ –Ω–µ –ø–æ–Ω–∏–º–∞–µ—Ç, –≥–¥–µ –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è/–∑–∞–∫–∞–Ω—á–∏–≤–∞–µ—Ç—Å—è —Ç–≤–æ–π –ø—Ä–æ–º–ø—Ç.[^10][^8][^9]

**–†–µ—à–µ–Ω–∏–µ:**

```python
# –ó–∞–º–µ–Ω–∏ build_instruction_text() –Ω–∞:
def format_with_native_template(example):
    messages = [
        {"role": "system", "content": SYSTEM_PROMPT},
        {"role": "user", "content": example["prompt"]},
        {"role": "assistant", "content": example["completion"]}
    ]
    # –ò—Å–ø–æ–ª—å–∑—É–π native chat template –º–æ–¥–µ–ª–∏
    text = tokenizer.apply_chat_template(
        messages,
        tokenize=False,
        add_generation_prompt=False
    )
    return {"text": text}
```

**–ü–æ—á–µ–º—É —ç—Ç–æ –≤–∞–∂–Ω–æ:**

- –ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç, —á—Ç–æ **–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π chat template** –¥–∞—ë—Ç +10-15% accuracy –Ω–∞ instruction tasks.[^8][^9][^10]
- –ú–æ–¥–µ–ª—å "–ø–æ–Ω–∏–º–∞–µ—Ç" —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–∏–∞–ª–æ–≥–∞ –∏ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç—ã –≤ –Ω—É–∂–Ω–æ–º –º–µ—Å—Ç–µ.[^9][^10][^8]

***

#### **3. –°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ target_modules –¥–ª—è conversational task**

```python
target_modules=["q_proj", "k_proj", "v_proj", "o_proj", "up_proj", "down_proj", "gate_proj"]
```

**–î–ª—è 1700 –ø—Ä–∏–º–µ—Ä–æ–≤:**

- –û–±—É—á–µ–Ω–∏–µ **MLP layers** (up_proj, down_proj, gate_proj) –Ω—É–∂–Ω–æ –¥–ª—è **reasoning/–∑–Ω–∞–Ω–∏–π**, –Ω–æ –Ω–µ –¥–ª—è **—Å—Ç–∏–ª—è –æ–±—â–µ–Ω–∏—è**.[^11][^12][^10]
- –î–ª—è –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω–æ–≥–æ –∫–ª–æ–Ω–∞ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ **—Ç–æ–ª—å–∫–æ attention**: `["q_proj", "k_proj", "v_proj", "o_proj"]`.[^12][^10][^11]

**–ü–æ—á–µ–º—É:**

- Attention –æ—Ç–≤–µ—á–∞–µ—Ç –∑–∞ "–∫–∞–∫ –æ—Ç–≤–µ—á–∞—Ç—å" (—Å—Ç–∏–ª—å, tone).[^11][^12]
- MLP –æ—Ç–≤–µ—á–∞–µ—Ç –∑–∞ "—á—Ç–æ –æ—Ç–≤–µ—á–∞—Ç—å" (—Ñ–∞–∫—Ç—ã, –∑–Ω–∞–Ω–∏—è).[^12][^11]
- –û–±—É—á–µ–Ω–∏–µ MLP –Ω–∞ —á–∞—Ç–∞—Ö –º–æ–∂–µ—Ç **–∏—Å–ø–æ—Ä—Ç–∏—Ç—å** –±–∞–∑–æ–≤—ã–µ –∑–Ω–∞–Ω–∏—è –º–æ–¥–µ–ª–∏.[^10][^11][^12]

***

#### **4. Learning rate —Å–ª–∏—à–∫–æ–º –≤—ã—Å–æ–∫ –¥–ª—è conversational fine-tuning**

```python
learning_rate=2e-4
```

**–ü—Ä–æ–±–ª–µ–º–∞:**

- 2e-4 ‚Äî —ç—Ç–æ —Å—Ç–∞–Ω–¥–∞—Ä—Ç –¥–ª—è **instruction tuning —Å –Ω—É–ª—è**.[^8][^9][^10]
- –î–ª—è **style adaptation** –Ω–∞ —É–∂–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–æ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ (Qwen2.5-7B-**Instruct**) –ª—É—á—à–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å **1e-4 –∏–ª–∏ –¥–∞–∂–µ 5e-5**.[^3][^1][^10]

**–ü–æ—á–µ–º—É:**

- –í—ã—Å–æ–∫–∏–π LR –º–æ–∂–µ—Ç "—Å–ª–æ–º–∞—Ç—å" –±–∞–∑–æ–≤—ã–µ capabilities –º–æ–¥–µ–ª–∏.[^1][^10]
- –ú–æ–¥–µ–ª—å –Ω–∞—á–∏–Ω–∞–µ—Ç "–∑–∞–±—ã–≤–∞—Ç—å", –∫–∞–∫ –æ—Ç–≤–µ—á–∞—Ç—å –Ω–∞ –æ–±—â–∏–µ –≤–æ–ø—Ä–æ—Å—ã, –∏ —Ñ–æ–∫—É—Å–∏—Ä—É–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –Ω–∞ —Ç–≤–æ–∏—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–∞—Ö.[^1][^10]

***

#### **5. Evaluation strategy = "epoch" (–Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω—ã–π –∫–æ–Ω—Ç—Ä–æ–ª—å)**

–ü—Ä–∏ 1700 –ø—Ä–∏–º–µ—Ä–∞—Ö —Å batch_size=4 –∏ grad_accum=4:

- –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–π batch = 16
- Steps per epoch = 1700 / 16 ‚âà **106 steps**

**–ü—Ä–æ–±–ª–µ–º–∞:**

- –¢—ã –≤–∏–¥–∏—à—å –º–µ—Ç—Ä–∏–∫–∏ —Ç–æ–ª—å–∫–æ 1 —Ä–∞–∑ –≤ —ç–ø–æ—Ö—É (106 —à–∞–≥–æ–≤).[^3][^1]
- –ï—Å–ª–∏ –º–æ–¥–µ–ª—å –Ω–∞—á–Ω—ë—Ç –ø–µ—Ä–µ–æ–±—É—á–∞—Ç—å—Å—è –Ω–∞ —à–∞–≥–µ 50 ‚Äî —Ç—ã —É–∑–Ω–∞–µ—à—å –æ–± —ç—Ç–æ–º —Ç–æ–ª—å–∫–æ –Ω–∞ —à–∞–≥–µ 106.[^3][^1]

**–†–µ—à–µ–Ω–∏–µ:**

```python
evaluation_strategy="steps",
eval_steps=50,  # –ø—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞–∂–¥—ã–µ 50 —à–∞–≥–æ–≤
```


***

#### **6. –û—Ç—Å—É—Ç—Å—Ç–≤–∏–µ early stopping**

–ë–µ–∑ early stopping –º–æ–¥–µ–ª—å –ø—Ä–æ–¥–æ–ª–∂–∞–µ—Ç –æ–±—É—á–∞—Ç—å—Å—è, –¥–∞–∂–µ –µ—Å–ª–∏ eval_loss —Ä–∞—Å—Ç—ë—Ç.[^4][^1][^3]

**–î–æ–±–∞–≤—å:**

```python
from transformers import EarlyStoppingCallback

callbacks=[
    EarlyStoppingCallback(
        early_stopping_patience=3,  # –æ—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø–æ—Å–ª–µ 3 —ç–ø–æ—Ö –±–µ–∑ —É–ª—É—á—à–µ–Ω–∏—è
        early_stopping_threshold=0.01
    )
]
```


***

## üöÄ **–ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –ø–ª–∞–Ω —É–ª—É—á—à–µ–Ω–∏–π (–¥–ª—è 1700 –ø—Ä–∏–º–µ—Ä–æ–≤)**

### **–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç 1: –ò—Å–ø—Ä–∞–≤—å chat template (—Å–∞–º–æ–µ –≤–∞–∂–Ω–æ–µ!)**

```python
# –í train_qlora.py –∑–∞–º–µ–Ω–∏ _format_with_context():
def _format_with_context(row: dict) -> dict:
    messages = [
        {"role": "system", "content": SYSTEM_PROMPT}
    ]
    
    # –î–æ–±–∞–≤—å –∏—Å—Ç–æ—Ä–∏—é –µ—Å–ª–∏ –µ—Å—Ç—å
    if row.get("history"):
        for turn in row["history"]:
            messages.append({"role": "user", "content": turn["user"]})
            messages.append({"role": "assistant", "content": turn["assistant"]})
    
    # –¢–µ–∫—É—â–∏–π –≤–æ–ø—Ä–æ—Å-–æ—Ç–≤–µ—Ç
    messages.append({"role": "user", "content": row["prompt"]})
    messages.append({"role": "assistant", "content": row["completion"]})
    
    # –ò—Å–ø–æ–ª—å–∑—É–π native template
    text = tokenizer.apply_chat_template(
        messages,
        tokenize=False,
        add_generation_prompt=False
    )
    return {"text": text}
```


***

### **–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç 2: –û—á–∏—Å—Ç–∏ –¥–∞—Ç–∞—Å–µ—Ç**

–î–æ–±–∞–≤—å –≤ `dataset_pipeline.py`:

```python
def clean_telegram_data(pairs):
    cleaned = []
    for p in pairs:
        # –§–∏–ª—å—Ç—Ä—É–π –∫–æ—Ä–æ—Ç–∫–∏–µ/–º—É—Å–æ—Ä–Ω—ã–µ
        if len(p["completion"].split()) < 5:
            continue
        # –£–¥–∞–ª—è–π —ç–º–æ–¥–∑–∏-only –æ—Ç–≤–µ—Ç—ã
        if all(c in 'üëçüëéüòäüòÇüî•üíØ' for c in p["completion"].strip()):
            continue
        cleaned.append(p)
    return cleaned
```


***

### **–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç 3: –°–Ω–∏–∑—å LR –∏ —É–º–µ–Ω—å—à–∏ target_modules**

```bash
!python train_qlora.py \
  --model-id Qwen/Qwen2.5-7B-Instruct \
  --epochs 5 \
  --batch-size 4 \
  --grad-accum 4 \
  --learning-rate 1e-4  # –≤–º–µ—Å—Ç–æ 2e-4
```

–í –∫–æ–¥–µ:

```python
target_modules=["q_proj", "k_proj", "v_proj", "o_proj"]  # —Ç–æ–ª—å–∫–æ attention
```


***

### **–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç 4: –î–æ–±–∞–≤—å eval_steps + early stopping**

```python
training_args = TrainingArguments(
    ...
    evaluation_strategy="steps",
    eval_steps=50,
    load_best_model_at_end=True,
    metric_for_best_model="eval_loss",
    ...
)

trainer = SFTTrainer(
    ...
    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]
)
```


***

## üìä **–û–∂–∏–¥–∞–µ–º—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ—Å–ª–µ —É–ª—É—á—à–µ–Ω–∏–π**

–° —É—á—ë—Ç–æ–º 1700 –ø—Ä–∏–º–µ—Ä–æ–≤ + –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –≤—ã—à–µ:

- **Eval loss –¥–æ–ª–∂–µ–Ω —É–ø–∞—Å—Ç—å –¥–æ 1.5-2.0** (—Å–µ–π—á–∞—Å 2.8).[^2][^1]
- **Mean token accuracy: 0.55-0.65** (—Å–µ–π—á–∞—Å 0.44).[^2][^1]
- **–ö–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ**: –º–æ–¥–µ–ª—å –±—É–¥–µ—Ç –æ—Ç–≤–µ—á–∞—Ç—å –≤ —Ç–≤–æ—ë–º —Å—Ç–∏–ª–µ –Ω–∞ 70-80% –≤–æ–ø—Ä–æ—Å–æ–≤.[^1][^2]

***

## üéØ **–ü–æ—á–µ–º—É –º–æ–¥–µ–ª—å —Å–µ–π—á–∞—Å "–≥–æ–≤–æ—Ä–∏—Ç –æ –¥—Ä—É–≥–æ–º"?**

–°–∫–æ—Ä–µ–µ –≤—Å–µ–≥–æ –∫–æ–º–±–∏–Ω–∞—Ü–∏—è:

1. **–ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π chat template** ‚Üí –º–æ–¥–µ–ª—å –Ω–µ –ø–æ–Ω–∏–º–∞–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Ç–≤–æ–∏—Ö –ø—Ä–æ–º–ø—Ç–æ–≤ (80% –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å).[^9][^10][^8]
2. **–í—ã—Å–æ–∫–∏–π LR** ‚Üí –º–æ–¥–µ–ª—å "–ø–µ—Ä–µ–æ–±—É—á–∏–ª–∞—Å—å" –∏ –ø–æ—Ç–µ—Ä—è–ª–∞ –±–∞–∑–æ–≤—ã–µ –Ω–∞–≤—ã–∫–∏ (15% –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å).[^10][^1]
3. **–®—É–º –≤ –¥–∞–Ω–Ω—ã—Ö** ‚Üí –º–Ω–æ–≥–æ –∫–æ—Ä–æ—Ç–∫–∏—Ö/–±–µ—Å—Å–º—ã—Å–ª–µ–Ω–Ω—ã—Ö –ø–∞—Ä –∏–∑ Telegram (5% –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å).[^6][^5]

***

**–ù–∞—á–Ω–∏ —Å –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è chat template (\#1) ‚Äî —ç—Ç–æ –¥–∞—Å—Ç —Å–∞–º—ã–π –±–æ–ª—å—à–æ–π —ç—Ñ—Ñ–µ–∫—Ç!** –ï—Å–ª–∏ –ø–æ—Å–ª–µ —ç—Ç–æ–≥–æ –≤—Å—ë –µ—â—ë –ø–ª–æ—Ö–æ ‚Äî –ø—Ä–∏–º–µ–Ω—è–π –æ—Å—Ç–∞–ª—å–Ω—ã–µ —É–ª—É—á—à–µ–Ω–∏—è –ø–æ –ø–æ—Ä—è–¥–∫—É.


[^1]: https://www.sapien.io/blog/strategies-for-fine-tuning-llms-on-small-datasets

[^2]: https://arxiv.org/html/2412.13337v1

[^3]: https://dialzara.com/blog/fine-tuning-llms-with-small-data-guide

[^4]: https://milvus.io/ai-quick-reference/how-do-you-handle-overfitting-in-small-datasets

[^5]: https://www.reddit.com/r/OpenAI/comments/1al8eol/how_to_detect_bad_data_in_your_instruction_tuning/

[^6]: https://cleanlab.ai/blog/filter-llm-tuning-data/

[^7]: https://arxiv.org/pdf/2311.13246.pdf

[^8]: https://www.philschmid.de/fine-tune-llms-in-2025

[^9]: https://collabnix.com/how-to-fine-tune-llm-and-use-it-with-ollama-a-complete-guide-for-2025/

[^10]: https://machinelearningmastery.com/the-machine-learning-practitioners-guide-to-fine-tuning-language-models/

[^11]: https://watercrawl.dev/blog/LoRA-and-QLoRA

[^12]: https://www.digitaldividedata.com/blog/ai-fine-tuning-techniques-lora-qlora-and-adapters

