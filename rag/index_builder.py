from __future__ import annotations

import argparse
import json
import logging
from dataclasses import dataclass
from pathlib import Path
from typing import Iterable, List, Sequence

import numpy as np
from datasets import load_dataset  # type: ignore

from dataset_pipeline.core.utils import ensure_directory
from .embeddings import get_embedding_backend

logger = logging.getLogger(__name__)


DEFAULT_KNOWLEDGE_FILE = "data/processed_dataset/knowledge/knowledge_chunks.jsonl"
DEFAULT_OUTPUT_DIR = Path("data/rag_index")


@dataclass
class KnowledgeRecord:
    content: str
    source: str | None = None
    metadata: dict | None = None


def parse_record(example: dict) -> KnowledgeRecord | None:
    content = str(example.get("content") or "").strip()
    if not content:
        return None
    source = example.get("source")
    metadata = example.get("metadata") if isinstance(example.get("metadata"), dict) else None
    return KnowledgeRecord(content=content, source=source, metadata=metadata)


def load_records(path: Path) -> List[KnowledgeRecord]:
    logger.info("Loading knowledge file %s", path)
    dataset = load_dataset("json", data_files=str(path), split="train")
    records: List[KnowledgeRecord] = []
    for example in dataset:
        record = parse_record(example)
        if record:
            records.append(record)
    logger.info("Collected %d knowledge chunks.", len(records))
    return records


def encode_records(records: Sequence[KnowledgeRecord], model_name: str) -> np.ndarray:
    backend = get_embedding_backend(model_name)
    texts = [record.content for record in records]
    embeddings = backend.encode(texts, normalize=True)
    logger.info("Embeddings shape: %s", embeddings.shape)
    return embeddings.astype(np.float32)


def save_index(output_dir: Path, embeddings: np.ndarray, records: Sequence[KnowledgeRecord]) -> None:
    ensure_directory(output_dir)
    embeddings_path = output_dir / "embeddings.npy"
    metadata_path = output_dir / "records.jsonl"

    np.save(embeddings_path, embeddings)
    with metadata_path.open("w", encoding="utf-8") as handle:
        for record in records:
            payload = {
                "content": record.content,
                "source": record.source,
                "metadata": record.metadata,
            }
            handle.write(json.dumps(payload, ensure_ascii=False) + "\n")
    logger.info("Index saved to %s", output_dir)


def build_index(
    knowledge_file: Path,
    output_dir: Path,
    model_name: str,
) -> None:
    records = load_records(knowledge_file)
    if not records:
        raise ValueError(f"No knowledge records found in {knowledge_file}")
    embeddings = encode_records(records, model_name=model_name)
    save_index(output_dir=output_dir, embeddings=embeddings, records=records)


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(description="Build RAG index from knowledge JSONL.")
    parser.add_argument(
        "--knowledge-file",
        type=Path,
        default=Path(DEFAULT_KNOWLEDGE_FILE),
        help="Path to knowledge_chunks.jsonl generated by dataset pipeline.",
    )
    parser.add_argument(
        "--output-dir",
        type=Path,
        default=DEFAULT_OUTPUT_DIR,
        help="Directory to store embeddings and metadata.",
    )
    parser.add_argument(
        "--embedding-model",
        default="sentence-transformers/all-MiniLM-L6-v2",
        help="Sentence-transformers model id for embeddings.",
    )
    parser.add_argument(
        "--log-level",
        default="INFO",
        choices=["DEBUG", "INFO", "WARNING", "ERROR"],
        help="Logging verbosity.",
    )
    return parser.parse_args()


def main() -> None:
    args = parse_args()
    logging.basicConfig(
        level=getattr(logging, args.log_level.upper(), logging.INFO),
        format="%(asctime)s [%(levelname)s] %(name)s: %(message)s",
    )

    if not args.knowledge_file.exists():
        raise FileNotFoundError(f"Knowledge file not found: {args.knowledge_file}")

    build_index(
        knowledge_file=args.knowledge_file,
        output_dir=args.output_dir,
        model_name=args.embedding_model,
    )


if __name__ == "__main__":
    main()
